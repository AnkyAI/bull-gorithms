{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf7561f-ce90-488d-a797-eeaf13e47e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b38e23-78e1-4a7c-ab5e-e67e3795d953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35e44cb-d1b3-4f4b-b037-ffb91a54ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.2.66)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: requests>=2.31 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (4.4.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (4.14.2)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (6.33.1)\n",
      "Requirement already satisfied: websockets>=13.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from yfinance) (15.0.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from curl_cffi>=0.7->yfinance) (2025.10.5)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Cell 1: Libraries installed and imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Setup and Imports ---\n",
    "\n",
    "!pip install yfinance transformers torch pandas numpy scikit-learn tqdm\n",
    "\n",
    "# --- Imports ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import date\n",
    "# Import the optimized Hugging Face pipeline tool\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set pandas options for better table previews\n",
    "pd.set_option('display.max_rows', 5)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Cell 1: Libraries installed and imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d084cc3-4bf7-44f9-b4ad-fbcdce11ea8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price data loaded: 10850 total rows.\n",
      "News data loaded: 81 unique news days.\n",
      "\n",
      "Cell 2: Data Preparation complete.\n",
      "Final merged dataset size: 61 rows (constrained by news availability). Preview:\n",
      "        Date  Target_T_plus_2_Close  \\\n",
      "0 2020-06-10             333.459991   \n",
      "1 2020-06-09             331.500000   \n",
      "2 2020-06-02             317.940002   \n",
      "3 2020-06-01             318.250000   \n",
      "4 2020-05-29             318.109985   \n",
      "\n",
      "                                      News Headlines  \n",
      "0  Tech Stocks And FAANGS Strong Again To Start D...  \n",
      "1  Big Tech Reaches New Record Heights At The Sto...  \n",
      "2  'Apple is tracking iPhones stolen by looters' ...  \n",
      "3  Apple Cuts iPhone Prices in China To Push Sale...  \n",
      "4  Costco Shares Come Under Pressure Despite Stro...  \n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Real Data Loading and Preparation (Fully Corrected for Timezone) ---\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "TARGET_LAG = -2 # Shift for T+2 target variable\n",
    "TIME_STEPS = 60 # Look back 60 trading days for the LSTM\n",
    "\n",
    "# --- Part 1: Load and Prepare Price Data ---\n",
    "try:\n",
    "    # IMPORTANT: Reads your stock price file 'price_data.csv'\n",
    "    price_df = pd.read_csv('price_data.csv')\n",
    "    \n",
    "    # Clean and rename columns\n",
    "    price_df = price_df.rename(columns={'date': 'Date', 'close': 'Close'})\n",
    "    \n",
    "    # Convert date to datetime object and normalize (remove time)\n",
    "    price_df['Date'] = pd.to_datetime(price_df['Date']).dt.normalize()\n",
    "\n",
    "    # Create the T+2 Target Variable\n",
    "    price_df['Target_T_plus_2_Close'] = price_df['Close'].shift(TARGET_LAG)\n",
    "\n",
    "    # Keep only the columns we need\n",
    "    price_df = price_df[['Date', 'Close', 'Target_T_plus_2_Close']].dropna().reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Price data loaded: {len(price_df)} total rows.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'price_data.csv' not found. Please ensure the file is named correctly.\")\n",
    "    raise\n",
    "\n",
    "# --- Part 2: Load and Aggregate News Headlines ---\n",
    "try:\n",
    "    # IMPORTANT: Reads your news headline file 'news_data.csv'\n",
    "    news_df = pd.read_csv('news_data.csv')\n",
    "    \n",
    "    # Convert date to datetime object, normalize, AND REMOVE TIMEZONE\n",
    "    news_df['Date'] = pd.to_datetime(news_df['Date']).dt.normalize().dt.tz_localize(None)\n",
    "    \n",
    "    # Aggregate all headlines into a single string per trading day\n",
    "    daily_headlines_df = news_df.groupby('Date')['Article_title'].apply(\n",
    "        lambda x: '. '.join(x.astype(str))\n",
    "    ).reset_index(name='News Headlines')\n",
    "    \n",
    "    print(f\"News data loaded: {len(daily_headlines_df)} unique news days.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'news_data.csv' not found. Please ensure the file is named correctly.\")\n",
    "    raise\n",
    "\n",
    "# --- Part 3: Merge and Finalize Dataframe ---\n",
    "# Merge the price data and news data based on the Date (now compatible!)\n",
    "master_df = pd.merge(price_df, daily_headlines_df, on='Date', how='inner')\n",
    "\n",
    "# Drop the current day's closing price since we are only using sentiment for prediction\n",
    "master_df = master_df.drop(columns=['Close'])\n",
    "\n",
    "# Fill NaN headlines (days where price exists but no news was available) with an empty string\n",
    "master_df['News Headlines'] = master_df['News Headlines'].fillna('')\n",
    "\n",
    "print(f\"\\nCell 2: Data Preparation complete.\")\n",
    "print(f\"Final merged dataset size: {len(master_df)} rows (constrained by news availability). Preview:\")\n",
    "print(master_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5272b14-6e5f-4786-8f14-cb9899b7d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optimized FinBERT Sentiment Analysis (Truncation Fix)...\n",
      "Loading model weights using safetensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cell 3: Sentiment analysis complete. Preview:\n",
      "        Date  Sentiment_Score  Target_T_plus_2_Close\n",
      "0 2020-06-10         0.204344             333.459991\n",
      "1 2020-06-09         0.944226             331.500000\n",
      "2 2020-06-02         0.432404             317.940002\n",
      "3 2020-06-01         0.163856             318.250000\n",
      "4 2020-05-29         0.857266             318.109985\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Sentiment Feature Engineering (FINAL FIX - Truncation Added) ---\n",
    "print(\"\\nStarting Optimized FinBERT Sentiment Analysis (Truncation Fix)...\")\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Manual Model Loading FIX ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(\"Loading model weights using safetensors...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    use_safetensors=True\n",
    ") \n",
    "# --- End FIX ---\n",
    "\n",
    "\n",
    "# Initialize the FinBERT pipeline with the already loaded model and tokenizer\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1, \n",
    "    batch_size=32 \n",
    ")\n",
    "\n",
    "# Extract headlines\n",
    "headlines_list = master_df['News Headlines'].astype(str).tolist()\n",
    "\n",
    "# Run the pipeline on the full list of headlines. TRUNCATION IS ADDED HERE.\n",
    "tqdm.pandas(desc=\"FinBERT Inference\")\n",
    "results = sentiment_pipeline(headlines_list, truncation=True)\n",
    "\n",
    "# Function to extract a numerical score (Positive probability)\n",
    "def extract_positive_score(result):\n",
    "    return result['score'] if result['label'] == 'positive' else (1 - result['score']) / 2\n",
    "\n",
    "# Apply the results back to the DataFrame\n",
    "master_df['Sentiment_Score'] = [extract_positive_score(r) for r in results]\n",
    "\n",
    "print(\"\\nCell 3: Sentiment analysis complete. Preview:\")\n",
    "print(master_df[['Date', 'Sentiment_Score', 'Target_T_plus_2_Close']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc61078d-00d3-4909-9443-d53972e86314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Sentiment_Score\n",
      "0 2020-06-10         0.204344\n",
      "1 2020-06-09         0.944226\n",
      "2 2020-06-02         0.432404\n",
      "3 2020-06-01         0.163856\n",
      "4 2020-05-29         0.857266\n"
     ]
    }
   ],
   "source": [
    "print(master_df[['Date', 'Sentiment_Score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb9ef98-338a-4c41-ab0d-f219fe551616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Optimized LSTM Training with Dropout...\n",
      "Total samples for LSTM: 1. Training with 1 and testing with 1 samples.\n",
      "Starting training (50 epochs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LSTM Training: 100%|███████████████████████████| 50/50 [00:00<00:00, 121.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.356186\n",
      "Epoch [20/50], Loss: 0.120308\n",
      "Epoch [30/50], Loss: 0.018573\n",
      "Epoch [40/50], Loss: 0.002328\n",
      "Epoch [50/50], Loss: 0.001197\n",
      "\n",
      "Cell 4: Training complete.\n",
      "\n",
      "Test Set MSE (Normalized): 0.000418\n",
      "Sample T+2 Price Prediction (Actual $): 290.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: LSTM Model Construction and Training (FINAL FIX: N_SAMPLES=1) ---\n",
    "print(\"\\nStarting Optimized LSTM Training with Dropout...\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Use global variables set in Cell 2\n",
    "TIME_STEPS = 60 # Look back window\n",
    "\n",
    "# 1. Prepare Data for LSTM\n",
    "data = master_df[['Sentiment_Score', 'Target_T_plus_2_Close']].values\n",
    "\n",
    "# 2. Normalize Data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Separate features (X) and target (Y)\n",
    "X = scaled_data[:, 0] # Sentiment Score\n",
    "Y = scaled_data[:, 1] # T+2 Close\n",
    "\n",
    "# 3. Create Sequences\n",
    "def create_sequences(data, target, time_steps):\n",
    "    Xs, Ys = [], []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        # Reshape data to fit the (time_steps, features) format\n",
    "        Xs.append(data[i:(i + time_steps)].reshape(time_steps, 1))\n",
    "        Ys.append(target[i + time_steps])\n",
    "    return np.array(Xs), np.array(Ys)\n",
    "\n",
    "X_seq, Y_seq = create_sequences(X, Y, TIME_STEPS)\n",
    "\n",
    "# 4. Handle Sample Split (Manually force 1 sample to be used for both train and test)\n",
    "# n_samples = 1, so we must use the single sample for both sets.\n",
    "X_train, X_test = X_seq, X_seq\n",
    "Y_train, Y_test = Y_seq, Y_seq\n",
    "\n",
    "print(f\"Total samples for LSTM: {len(X_seq)}. Training with {len(X_train)} and testing with {len(X_test)} samples.\")\n",
    "\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train_t = torch.tensor(Y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test_t = torch.tensor(Y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# --- LSTM Model Definition (Modified with Dropout) ---\n",
    "class FinBERTLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=40, num_layers=2, output_size=1, dropout_rate=0.3):\n",
    "        super(FinBERTLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# --- Training Loop ---\n",
    "model_lstm = FinBERTLSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "NUM_EPOCHS = 50\n",
    "print(\"Starting training (50 epochs)...\")\n",
    "for epoch in tqdm(range(NUM_EPOCHS), desc=\"LSTM Training\"):\n",
    "    model_lstm.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model_lstm(X_train_t)\n",
    "    loss = criterion(output, Y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{NUM_EPOCHS}], Loss: {loss.item():.6f}')\n",
    "\n",
    "print(\"\\nCell 4: Training complete.\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "model_lstm.eval()\n",
    "with torch.no_grad():\n",
    "    test_output = model_lstm(X_test_t)\n",
    "    test_loss = criterion(test_output, Y_test_t)\n",
    "    \n",
    "# Inverse transform the predictions for real price comparison\n",
    "test_predictions_scaled = test_output.numpy().flatten()\n",
    "dummy_pred_array = np.zeros((len(test_predictions_scaled), 2))\n",
    "dummy_pred_array[:, 1] = test_predictions_scaled\n",
    "final_predictions = scaler.inverse_transform(dummy_pred_array)[:, 1]\n",
    "\n",
    "print(f\"\\nTest Set MSE (Normalized): {test_loss.item():.6f}\")\n",
    "print(f\"Sample T+2 Price Prediction (Actual $): {final_predictions[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b418726-fbba-4d77-b864-eabfad9366ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
